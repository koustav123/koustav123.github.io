<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="icon" href="">

    <title>Koustav Ghosal</title>

    <!-- Bootstrap core CSS -->
    <link href="bootstrap-3.3.6/docs/dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <link href="bootstrap-3.3.6/docs/assets/css/ie10-viewport-bug-workaround.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="starter-template.css" rel="stylesheet">

    <!-- Just for debugging purposes. Don't actually copy these 2 lines! -->
    <!--[if lt IE 9]>
    <script src="../../assets/js/ie8-responsive-file-warning.js"></script><![endif]-->
    <script src="bootstrap-3.3.6/docs/assets/js/ie-emulation-modes-warning.js"></script>

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
</head>

<body>

<nav class="navbar navbar-inverse navbar-fixed-top">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar"
                    aria-expanded="false" aria-controls="navbar">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <!--  <a class="navbar-brand" href="#">Koustav Ghosal</a> -->
        </div>
        <div id="navbar" class="collapse navbar-collapse">
            <ul class="nav navbar-nav">
                <li><a href="index.html">Home</a></li>
<!--                <li class="active"><a href="#publications">Publications</a></li>-->
                <li><a href="education.html">Education</a></li>
                <!--			<li ><a href="projects.html">Projects</a></li>-->
                <li><a href="experiences.html">Experience</a></li>
                <li><a href="files/Resume.pdf" target="tab">Resume</a></li>
                <!--            <li><a href="moreAboutMe.html">More about me</a></li>-->
            </ul>
        </div><!--/.nav-collapse -->
    </div>
</nav>

<div class="container">
    <div class="starter-template-small" style="background-color:Coral;">

        <h2 align="left">Publications </h2>
        | <a href="https://scholar.google.com/citations?user=Q2-PDhUAAAAJ&hl=en" target="tab">Google Scholar</a>
        | <a href="https://www.semanticscholar.org/author/Koustav-Ghosal/19444389" target="tab">Semantic Scholar</a>
        | <a href="https://www.researchgate.net/profile/Koustav_Ghosal" target="tab">ResearchGate</a> |

    </div>
    <ul class="list-group" align="justify">
        <li class="list-group-item"><h4> Koustav Ghosal, Aljosa Smolic <b>Image Aesthetics Assessment Using Graph
            Attention Network
        </b>IEEE Transactions on Image Processing (2021) (under review)
            <!--            <a href=https://link.springer.com/article/10.1007/s11760-021-01915-4" target="_tab">[paper]</a>-->
            <!--                                    <a href="https://github.com/V-Sense/Aesthetic-Image-Captioning-ICCVW-2019.git" target="tab">[code]</a>-->

        </h4>
            <p></p>
        </li>

        <li class="list-group-item"><h4> Ojasvi Yadav, Koustav Ghosal, Sebastian Lutz, Aljosa Smolic <b>Frequency-domain
            loss function for
            deep exposure correction of dark images
        </b>Signal, Image and Video Processing (2021)
            <a href=https://link.springer.com/article/10.1007/s11760-021-01915-4" target="_tab">[paper]</a>
            <!--                                    <a href="https://github.com/V-Sense/Aesthetic-Image-Captioning-ICCVW-2019.git" target="tab">[code]</a>-->

        </h4>
            <p></p>
        </li>

        <li class="list-group-item"><h4> Koustav Ghosal, Aakanksha Rana, Aljosa Smolic <b>Aesthetic Image Captioning
            From Weakly-Labelled Photographs
        </b>The IEEE International Conference on Computer Vision (ICCV-W), 2019
            <a href="http://openaccess.thecvf.com/content_ICCVW_2019/html/CROMOL/Ghosal_Aesthetic_Image_Captioning_From_Weakly-Labelled_Photographs_ICCVW_2019_paper.html"
               target="_tab">[paper]</a>
            <a href="https://github.com/V-Sense/Aesthetic-Image-Captioning-ICCVW-2019.git" target="tab">[code]</a>

        </h4>
            <p></p>
        </li>

        <li class="list-group-item"><h4> Xu Zheng, Tejo Chalasani, Koustav Ghosal, Sebastian Lutz, Aljosa Smolic <b>STaDA:
            Style Transfer as Data Augmentation
        </b>14th International Conference on Computer Vision Theory and Applications, 2019.
            <a href="https://v-sense.scss.tcd.ie/wp-content/uploads/2019/05/STaDA-StyleTransferasDataAugmentation-1.pdf"
               target="_tab">[paper]</a>
        </h4>
            <p></p>
        </li>
        <li class="list-group-item"><h4>Koustav Ghosal, Mukta Prasad, Aljosa Smolic, <b>A Geometry-Sensitive Approach
            for Photographic Style Classification </b>, Irish Machine Vision and Image Processing Conference, August
            2018 (IMVIP), Belfast.
            <a href="https://v-sense.scss.tcd.ie/wp-content/uploads/2018/08/IMVIP_2018_paper_2-2.pdf" target="_tab">[paper]</a>
            <a href="https://v-sense.scss.tcd.ie/wp-content/uploads/2018/08/IMVIP_2018_KOUSTAV_SLIDES.pdf" target="tab">[slides]</a>
            <a href="https://github.com/V-Sense/A-Geometry-Sensitive-Approach-for-Photographic-Style-Classification.git"
               target="tab">[code]</a>
        </h4>
            <p></p>
        </li>

        <li class="list-group-item"><h4>Koustav Ghosal, Ameya Prabhu, Riddhiman Dasgupta, Anoop M. Namboodiri, <b>Learning
            Clustered Sub-spaces for sketch-based Image Retrieval</b>, Asian Conference on Pattern Recognition, November
            2015, Kuala Lumpur, Malaysia.
            <a href="files/Ghosal_Prabhu_DG_Namboodiri_SBIR_CR_431.pdf" target="_tab">[paper]</a>
            <a href="files/Koustav-ACPR15-431_Final.pdf" target="tab">[slides]</a>
        </h4>
            <p></p>
        </li>
        <li class="list-group-item"><h4>Koustav Ghosal, Anoop M. Namboodiri, <b>A Sketch-Based Approach to Video
            Retrieval using
            Qualitative Features</b>, Proceedings of the Ninth Indian Conference on Computer Vision, Graphics
            and Image Processing, 14-17 Dec 2014, Bangalore, India.
            <a href="files/Koustav2014Asketch.pdf" target="_tab">[paper]</a>
            <a href="files/Koustav-ICVGIP14-204.pdf" target="tab">[slides]</a>
            <a href="https://github.com/koustav123/A-Sketch-Based-Approach-to-Video-Retrieval-using-Qualitative-Features.git"
               target='tab'>[code]</a>
        </h4>
            <p></p>
        </li>
        <li class="list-group-item"><h4>Sanchit Aggarawal, Koustav Ghosal, Pulkit Singhal, Priyanka Srivastava, <b>Effect
            of Learning on
            Audio Spatial Working Memory</b>, Spatial Cognition 2014, Bremen, Germany, 15-19 September
            2014.
            <a href="files/sc2014_submission_56.pdf" target="_tab">[paper]</a>
            <a href="files/SC_Poster_Final.pdf" target="tab">[poster]</a>
        </h4>
            <p></p>
        </li>
    </ul>
    <div class="starter-template-small" style="background-color:Coral;">

        <h2 align="left">Thesis</h2>
    </div>
    <ul class="list-group" align="justify">
        <li class="list-group-item"><h4>PhD Thesis : Applications in Image Aesthetics Using Deep
            Learning: Attribute Prediction, Image Captioning
            and Score Regression <a
                    href="files/Dissertation_Koustav.pdf" target="_tab">[pdf]</a>
            <!--            <a href="files/Thesis_Koustav_Ghosal_2.pdf" target="tab">[slides]</a>-->
        </h4>
            <p><b>Abstract :</b> Image Aesthetics refers to the branch of computer vision which is about the study of
                aesthetic properties of photographs <i>ie.</i> the factors which make an image look pleasing or dull. Such
                factors extend beyond the physical properties of an image such as object category or location to subtler
                and more nuanced ambiguous concepts such as ``candid expression'', ``harsh lighting'', ``bad placement''
                <i>etc.</i> Nevertheless, the problems in Image Aesthetics have traditionally been modelled as classical
                computer vision tasks such as classification, regression <i>etc.</i> And, as with most other problems in
                computer vision, deep learning based strategies have proved more effective in this area as well,
                outperforming the classical approaches by a wide margin. Nowadays, automated systems for Image
                Aesthetics Analysis have widespread applications from professional multimedia content development to
                casual creatives in social media and advertising.

                <p> In this thesis, we study three different applications in Image Aesthetics using deep learning: attribute
                classification, feedback and score prediction. First, we study the capacity of deep neural networks in
                capturing the geometric attributes <i>ie.</i> those which depend on the arrangement of objects within the
                image. Based on this, we propose a system that predicts the dominant aesthetic attributes in a
                photograph such as The Rule of Thirds, leading lines <i>etc.</i> Second, we develop an aesthetic image
                captioning framework by exploiting <i>in the wild</i> user feedback from the web. Given an image, our
                framework generates critical feedback such as ``<i>nice composition but the foreground is out of
                focus</i>''. Third, we investigate the limitations of traditional convolutional neural networks with
                respect to global relational reasoning and handling photographs of arbitrary aspect ratio and
                resolution. We present a visual attention based graph neural network that addresses these limitations
                and advances the state-of-the-art in aesthetic score prediction.</p>


        </li>
    </ul>
    <ul class="list-group" align="justify">
        <li class="list-group-item"><h4>Master's Thesis : A Sketch-based Approach for Multimedia Retrieval <a
                href="files/Koustav_Ghosal_Thesis_1.7.pdf" target="_tab">[pdf]</a>
            <a href="files/Thesis_Koustav_Ghosal_2.pdf" target="tab">[slides]</a>
        </h4>
            <p><b>Abstract :</b> A hand-drawn sketch is a convenient way to search for an image or a video from a
                database where examples are unavailable or textual queries are too difficult to articulate. In this
                thesis, we have tried to propose solutions for some problems in sketch-based multimedia retrieval. In
                case of image search, the queries could be approximate binary outlines of the actual objects. In case of
                videos, we consider the case where the user can specify the motion trajectory using a sketch, which is
                provided as a query.
            <p>However there are multiple problems associated with this paradigm. Firstly, different users sketch the
                same query differently according to their own perception of reality. Secondly, sketches are sparse and
                abstract representations of images and the two modalities can not be compared directly. Thirdly,
                compared to images, datasets of sketches are rare. It is very difficult, if not impossible to train a
                system with sketches of every possible category. The features should be robust enough to retrieve
                classes that were not a part of training.
            <p>In this thesis, the work can be broadly divided into three parts. First, we develop a motion-trajectory
                based video retrieval strategy and propose a representation for sketches that aims to reduce the
                perceptual variability among different users. We also propose a novel retrieval strategy, which combines
                multiple feature representations for a final result using a cumulative scoring mechanism.
            <p>In order to tackle the problem of multiple modalities, we propose a sketch-based image retrieval strategy
                by mapping the two modalities into a lower dimensional sub-space where they are maximally correlated. We
                use Cluster Canonical Correlation Analysis (c-CCA), a modified version of standard CCA, for the mapping.
            <p>Finally, we investigate the use of semantic features derived from a Convolutional Neural Network, and
                extend the idea of sketch-based image retrieval to the task of zero-shot learning or unknown class
                retrieval. We define an objective function for the network such that, while training, a close miss is
                penalized less than a distant miss. Our training encodes semantic similarity among the different
                classes. We perform experiments to evaluate our algorithms on well known datasets and our results show
                that our features perform reasonably well in challenging scenarios.</p>
        </li>
    </ul>

</div><!-- /.container -->


<!-- Bootstrap core JavaScript
================================================== -->
<!-- Placed at the end of the document so the pages load faster -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery.min.js"><\/script>')</script>
<script src="bootstrap-3.3.6/docs/dist/js/bootstrap.min.js"></script>
<!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
<script src="bootstrap-3.3.6/docs/assets/js/ie10-viewport-bug-workaround.js"></script>
</body>
</html>
