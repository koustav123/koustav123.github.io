<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="icon" href="figures/TrinityLogo.jpg">

    <title>Koustav Ghosal</title>

    <!-- Bootstrap core CSS -->
    <link href="bootstrap-3.3.6/docs/dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <link href="bootstrap-3.3.6/docs/assets/css/ie10-viewport-bug-workaround.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="starter-template.css" rel="stylesheet">

    <!-- Just for debugging purposes. Don't actually copy these 2 lines! -->
    <!--[if lt IE 9]>
    <script src="../../assets/js/ie8-responsive-file-warning.js"></script><![endif]-->
    <script src="bootstrap-3.3.6/docs/assets/js/ie-emulation-modes-warning.js"></script>

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <script src="jquery.js"></script>
    <![endif]-->
</head>

<body>

<nav class="navbar navbar-inverse navbar-fixed-top">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar"
                    aria-expanded="false" aria-controls="navbar">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <!--  <a class="navbar-brand" href="#">Koustav Ghosal</a> -->
        </div>
        <div id="navbar" class="collapse navbar-collapse">
            <ul class="nav navbar-nav">
                <li class="active"><a href="#">Home</a></li>
                <!--                <li><a href="publications.html">Publications</a></li>-->
                <!--                <li><a href="projects.html">Projects</a></li>-->
                <li><a href="education.html">Education</a></li>
                <li><a href="experiences.html">Experience</a></li>
                <li><a href="files/Resume.pdf" target="tab">Resume</a></li>
                <!--                <li><a href="moreAboutMe.html">More about me</a></li>-->
            </ul>
        </div><!--/.nav-collapse -->
    </div>
</nav>

<div class="container">
    <a href="figures/profilePic5.jpeg" target="_blank">
    <img align="left" style="width:20.75%" src="figures/profilePic5.jpeg"/>
        </a>
    <div class="jumbotron" style="background-color:#C7CACD;padding-top:10px;padding-bottom:10px;">

        <h2 align="right">Koustav Ghosal</h2>
        <p align="right" class="lead"><a href="https://v-sense.scss.tcd.ie/" target="tab">V-SENSE</a> <br> School of
            Computer Science and Statistics <br> Trinity College Dublin <br> ghosalk@tcd.ie <br><br>
            External Links:
            <a
                    href="https://scholar.google.com/citations?user=Q2-PDhUAAAAJ&hl=en" target="tab"> <img
                    src="figures/scholar_logo.jpg" alt="scholar" width="20" height="20"> </a>

            <a
                    href="https://www.semanticscholar.org/author/Koustav-Ghosal/19444389" target="tab"><img
                    src="figures/semantic_scholar_logo.png" alt="scholar" width="20" height="20">
            </a>
            <a href="https://www.researchgate.net/profile/Koustav_Ghosal" target="tab"><img
                    src="figures/RG_logo.png" alt="scholar" width="20" height="20">
            </a>
            <a
                    href="https://www.linkedin.com/in/koustav-ghosal-65a24624/" target="tab"> <img
                    src="figures/Linkedin-logo.png" alt="scholar" width="20" height="20"> </a>

            <a href="https://github.com/koustav123" target="tab"><img
                    src="figures/GitHub-logo.png" alt="scholar" width="20" height="20">

            </a></p>

    </div>
    <div class="container">
        <p align="justify">
            I am a postdoc at the V-SENSE lab in Trinity College Dublin. My current research is focused on
            developing applications for 3D human pose estimation and 3D mesh sequence compression using graph neural
            networks and vision transformers. I hold a PhD and a research masters in Computer Vision. </p>
        <p> I am passionate about problems in computer vision and natural language processing. SpeciÔ¨Åcally, I am
            interested
            in multitask learning, generative adversarial learning, semi and unsupervised learning.
        </p>


    </div>

    <div class="container">
        <h2>Research Interest</h2>
        Vision and Language, Noisy Data, Multitask Learning,
        Adversarial Learning, Non-Local and Graph Neural Networks, Transformers
        <!--        <p align="justify">I am interested in the area of <b> Computational Photography, Tracking, Video Summarization,-->
        <!--            Action Recognition and Multimedia Retrieval and Classification</b>. <br><br>-->
        <!--            During master's, my area of research was sketch based multimedia retrieval. A simple hand-drawn sketch is an-->
        <!--            effective way to summarize the content of an image or a video where the right keywords are imprecise and-->
        <!--            difficult to articulate. It was a multimodal retrieval problem. In my work, I proposed solutions for sketch-->
        <!--            based video and image retrieval. We tried to build retrieval systems using a combination of zero-shot and-->
        <!--            deep learning techniques. <br><br>-->

        <!--            The area of image and video analysis is quite interesting and active. Apart from retrieval and-->
        <!--            classification, it has a wide range of application areas like surveillance, traffic analysis, autonomous-->
        <!--            navigation and many more.</p>-->
    </div>

    <div class="container">
        <h2>Publications</h2>
        <ul class="list-group" align="justify">
            <li class="list-group-item"> Koustav Ghosal, Aljosa Smolic <b>Image Aesthetics Assessment Using Graph
                Attention Network
            </b>IEEE Transactions on Image Processing (2021) (under review)
                <!--            <a href=https://link.springer.com/article/10.1007/s11760-021-01915-4" target="_tab">[paper]</a>-->
                <!--                                    <a href="https://github.com/V-Sense/Aesthetic-Image-Captioning-ICCVW-2019.git" target="tab">[code]</a>-->
                <p></p>
            </li>

            <li class="list-group-item"> Ojasvi Yadav, Koustav Ghosal, Sebastian Lutz, Aljosa Smolic <b>Frequency-domain
                loss function for
                deep exposure correction of dark images
            </b>Signal, Image and Video Processing (2021)
                <a href=https://link.springer.com/article/10.1007/s11760-021-01915-4" target="_tab">[paper]</a>
                <!--                                    <a href="https://github.com/V-Sense/Aesthetic-Image-Captioning-ICCVW-2019.git" target="tab">[code]</a>-->

                <p></p>
            </li>

            <li class="list-group-item"> Koustav Ghosal, Aakanksha Rana, Aljosa Smolic <b>Aesthetic Image Captioning
                From Weakly-Labelled Photographs
            </b>The IEEE International Conference on Computer Vision (ICCV-W), 2019
                <a href="http://openaccess.thecvf.com/content_ICCVW_2019/html/CROMOL/Ghosal_Aesthetic_Image_Captioning_From_Weakly-Labelled_Photographs_ICCVW_2019_paper.html"
                   target="_tab">[paper]</a>
                <a href="https://github.com/V-Sense/Aesthetic-Image-Captioning-ICCVW-2019.git" target="tab">[code]</a>


                <p></p>
            </li>

            <li class="list-group-item"> Xu Zheng, Tejo Chalasani, Koustav Ghosal, Sebastian Lutz, Aljosa Smolic <b>STaDA:
                Style Transfer as Data Augmentation
            </b>14th International Conference on Computer Vision Theory and Applications, 2019.
                <a href="https://v-sense.scss.tcd.ie/wp-content/uploads/2019/05/STaDA-StyleTransferasDataAugmentation-1.pdf"
                   target="_tab">[paper]</a>
                <p></p>
            </li>
            <li class="list-group-item">Koustav Ghosal, Mukta Prasad, Aljosa Smolic, <b>A Geometry-Sensitive
                Approach
                for Photographic Style Classification </b>, Irish Machine Vision and Image Processing Conference, August
                2018 (IMVIP), Belfast.
                <a href="https://v-sense.scss.tcd.ie/wp-content/uploads/2018/08/IMVIP_2018_paper_2-2.pdf" target="_tab">[paper]</a>
                <a href="https://v-sense.scss.tcd.ie/wp-content/uploads/2018/08/IMVIP_2018_KOUSTAV_SLIDES.pdf"
                   target="tab">[slides]</a>
                <a href="https://github.com/V-Sense/A-Geometry-Sensitive-Approach-for-Photographic-Style-Classification.git"
                   target="tab">[code]</a>
                <p></p>
            </li>

            <li class="list-group-item">Koustav Ghosal, Ameya Prabhu, Riddhiman Dasgupta, Anoop M. Namboodiri, <b>Learning
                Clustered Sub-spaces for sketch-based Image Retrieval</b>, Asian Conference on Pattern Recognition,
                November
                2015, Kuala Lumpur, Malaysia.
                <a href="files/Ghosal_Prabhu_DG_Namboodiri_SBIR_CR_431.pdf" target="_tab">[paper]</a>
                <a href="files/Koustav-ACPR15-431_Final.pdf" target="tab">[slides]</a>
                <p></p>
            </li>
            <li class="list-group-item">Koustav Ghosal, Anoop M. Namboodiri, <b>A Sketch-Based Approach to Video
                Retrieval using
                Qualitative Features</b>, Proceedings of the Ninth Indian Conference on Computer Vision, Graphics
                and Image Processing, 14-17 Dec 2014, Bangalore, India.
                <a href="files/Koustav2014Asketch.pdf" target="_tab">[paper]</a>
                <a href="files/Koustav-ICVGIP14-204.pdf" target="tab">[slides]</a>
                <a href="https://github.com/koustav123/A-Sketch-Based-Approach-to-Video-Retrieval-using-Qualitative-Features.git"
                   target='tab'>[code]</a>
                <p></p>
            </li>
            <li class="list-group-item">Sanchit Aggarawal, Koustav Ghosal, Pulkit Singhal, Priyanka Srivastava, <b>Effect
                of Learning on
                Audio Spatial Working Memory</b>, Spatial Cognition 2014, Bremen, Germany, 15-19 September
                2014.
                <a href="files/sc2014_submission_56.pdf" target="_tab">[paper]</a>
                <a href="files/SC_Poster_Final.pdf" target="tab">[poster]</a>
                <p></p>
            </li>
        </ul>
    </div><!-- /.container -->
<!--    <div class="container">-->
<!--        <h2>Thesis</h2>-->
<!--        <ul class="list-group" align="justify">-->
<!--            <li class="list-group-item"><h4><b>PhD: Applications in Image Aesthetics Using Deep-->
<!--                Learning: Attribute Prediction, Image Captioning-->
<!--                and Score Regression </b><a-->
<!--                    href="files/Dissertation_Koustav.pdf" target="_tab">[pdf]</a>-->
<!--                &lt;!&ndash;            <a href="files/Thesis_Koustav_Ghosal_2.pdf" target="tab">[slides]</a>&ndash;&gt;-->
<!--            </h4>-->
<!--                <p><b>Abstract :</b> Image Aesthetics refers to the branch of computer vision which is about the study-->
<!--                    of-->
<!--                    aesthetic properties of photographs <i>ie.</i> the factors which make an image look pleasing or-->
<!--                    dull. Such-->
<!--                    factors extend beyond the physical properties of an image such as object category or location to-->
<!--                    subtler-->
<!--                    and more nuanced ambiguous concepts such as ``candid expression'', ``harsh lighting'', ``bad-->
<!--                    placement''-->
<!--                    <i>etc.</i> Nevertheless, the problems in Image Aesthetics have traditionally been modelled as-->
<!--                    classical-->
<!--                    computer vision tasks such as classification, regression <i>etc.</i> And, as with most other-->
<!--                    problems in-->
<!--                    computer vision, deep learning based strategies have proved more effective in this area as well,-->
<!--                    outperforming the classical approaches by a wide margin. Nowadays, automated systems for Image-->
<!--                    Aesthetics Analysis have widespread applications from professional multimedia content development to-->
<!--                    casual creatives in social media and advertising.-->

<!--                <p> In this thesis, we study three different applications in Image Aesthetics using deep learning:-->
<!--                    attribute-->
<!--                    classification, feedback and score prediction. First, we study the capacity of deep neural networks-->
<!--                    in-->
<!--                    capturing the geometric attributes <i>ie.</i> those which depend on the arrangement of objects-->
<!--                    within the-->
<!--                    image. Based on this, we propose a system that predicts the dominant aesthetic attributes in a-->
<!--                    photograph such as The Rule of Thirds, leading lines <i>etc.</i> Second, we develop an aesthetic-->
<!--                    image-->
<!--                    captioning framework by exploiting <i>in the wild</i> user feedback from the web. Given an image,-->
<!--                    our-->
<!--                    framework generates critical feedback such as ``<i>nice composition but the foreground is out of-->
<!--                        focus</i>''. Third, we investigate the limitations of traditional convolutional neural networks-->
<!--                    with-->
<!--                    respect to global relational reasoning and handling photographs of arbitrary aspect ratio and-->
<!--                    resolution. We present a visual attention based graph neural network that addresses these-->
<!--                    limitations-->
<!--                    and advances the state-of-the-art in aesthetic score prediction.</p>-->


<!--            </li>-->
<!--        </ul>-->
<!--        <ul class="list-group" align="justify">-->
<!--            <li class="list-group-item"><h4><b> Master's: A Sketch-based Approach for Multimedia Retrieval</b> <a-->
<!--                    href="files/Koustav_Ghosal_Thesis_1.7.pdf" target="_tab">[pdf]</a>-->
<!--                <a href="files/Thesis_Koustav_Ghosal_2.pdf" target="tab">[slides]</a>-->
<!--            </h4>-->
<!--                <p><b>Abstract :</b> A hand-drawn sketch is a convenient way to search for an image or a video from a-->
<!--                    database where examples are unavailable or textual queries are too difficult to articulate. In this-->
<!--                    thesis, we have tried to propose solutions for some problems in sketch-based multimedia retrieval.-->
<!--                    In-->
<!--                    case of image search, the queries could be approximate binary outlines of the actual objects. In-->
<!--                    case of-->
<!--                    videos, we consider the case where the user can specify the motion trajectory using a sketch, which-->
<!--                    is-->
<!--                    provided as a query.-->
<!--                <p>However there are multiple problems associated with this paradigm. Firstly, different users sketch-->
<!--                    the-->
<!--                    same query differently according to their own perception of reality. Secondly, sketches are sparse-->
<!--                    and-->
<!--                    abstract representations of images and the two modalities can not be compared directly. Thirdly,-->
<!--                    compared to images, datasets of sketches are rare. It is very difficult, if not impossible to train-->
<!--                    a-->
<!--                    system with sketches of every possible category. The features should be robust enough to retrieve-->
<!--                    classes that were not a part of training.-->
<!--                <p>In this thesis, the work can be broadly divided into three parts. First, we develop a-->
<!--                    motion-trajectory-->
<!--                    based video retrieval strategy and propose a representation for sketches that aims to reduce the-->
<!--                    perceptual variability among different users. We also propose a novel retrieval strategy, which-->
<!--                    combines-->
<!--                    multiple feature representations for a final result using a cumulative scoring mechanism.-->
<!--                <p>In order to tackle the problem of multiple modalities, we propose a sketch-based image retrieval-->
<!--                    strategy-->
<!--                    by mapping the two modalities into a lower dimensional sub-space where they are maximally-->
<!--                    correlated. We-->
<!--                    use Cluster Canonical Correlation Analysis (c-CCA), a modified version of standard CCA, for the-->
<!--                    mapping.-->
<!--                <p>Finally, we investigate the use of semantic features derived from a Convolutional Neural Network, and-->
<!--                    extend the idea of sketch-based image retrieval to the task of zero-shot learning or unknown class-->
<!--                    retrieval. We define an objective function for the network such that, while training, a close miss-->
<!--                    is-->
<!--                    penalized less than a distant miss. Our training encodes semantic similarity among the different-->
<!--                    classes. We perform experiments to evaluate our algorithms on well known datasets and our results-->
<!--                    show-->
<!--                    that our features perform reasonably well in challenging scenarios.</p>-->
<!--            </li>-->
<!--        </ul>-->
<!--    </div>-->
    </img>

</div><!-- /.container -->


<!-- Bootstrap core JavaScript
================================================== -->
<!-- Placed at the end of the document so the pages load faster -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery.min.js"><\/script>')</script>
<script src="bootstrap-3.3.6/docs/dist/js/bootstrap.min.js"></script>
<!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
<script src="bootstrap-3.3.6/docs/assets/js/ie10-viewport-bug-workaround.js"></script>
</body>
</html>
